\subsection{Potential of Future Computing Platforms}
The landscape of future computing platforms is diverse, consisting of conventional multicore systems, hardware multithreaded sytems, mobile and embedded systems (e.g., ARM, Intel Atom), manycore co-processor accelerated systems (e.g., GPGPUs, Intel Xeon Phi), and systems with special function and/or reconfigurable (e.g., FPGA) hardware.
These offer different degrees of general applicability,
performance and power efficiencies, and technological risk~\cite{Choi:2014bb}.
Each platform exposes new
opportunities within our focal science areas, but no single platform best serves every opportunity
for accelerating scientific breakthroughs. 
Here, we briefly describe the platforms and highlight
known applications. Computational technology often progresses more rapidly than science, and the
emerging computing platforms of today will form tomorrow's CI.

\textbf{XXX: Add something about hybrid memory, etc.}

\subsubsection{High-level design space: multicore, manycore, and hardware multithreading}
The main mechanism for exploiting parallelism is to assemble a parallel processor from general-purpose cores, where each core can execute a sequential task fully independently from other cores.
The main reason for replicating cores is power:
increasing the number of cores improves performance linearly while also improving power only linearly, which is better than the superlinear (quadratic or higher) increases in power required to make an individual core faster~\cite{patterson:2010:spectrum}.

Specific processor and system designs differ primarily in the number of cores per chip and, since one may regard chip area as being largely fixed, the features and capabilities of each core.
In particular, one design might have relatively few cores where each core uses more area (i.e., more transistors) to include mechanisms that will make a sequential task take less time;
whereas another design might have relatively many cores that sacrifice per-thread time in favor of more overall concurrency.
These design contrasts are sometimes referred to as choosing between ``brawny'' versus ``wimpy'' cores or alternatively ``latency-optimized'' versus ``throughput-optimized'' cores~\cite{Holzle2010,Garland2010b}.

Designs based on latency-optimized or brawny cores---including x86, IBM POWER, and SPARC64 architectures, for example~\cite{power8,sparcm6,intel-ivytown}---are most useful when the target workload consists of general-purpose programs with relatively low degrees of thread-level parallelism.
The vast majority of existing programs fall into this category, owing to the huge investments in developing software primarily with sequential execution in mind.
This class of processor designs fill an important niche in scientific processing because of their flexibility,
programmability (owing, for instance, to automatic cache management and support for relatively low-degrees of data parallelism within tasks via short-vector processing or SIMD units), and ability to execute control-intensive algorithms efficiently~\cite{Kang2009,Williams2009,aparna.fmm}.
Moreover, software development costs will increase dramatically as a desire to exploit more cores increases, since increasing concurrency tends to make software engineering, testing, and debugging much more challenging~\cite{conf/sc/MattsonRLBHKHVBRD10,Asanovic:2009:VPC:1562764.1562783}.

By contrast, designs based on throughput-optimized or wimpy cores---including most GPGPUs, Intel Xeon Phi (``MIC''), and emerging embedded accelerators~\cite{Bell2008,ATI.Stream,intel.mic,TileGX8100}---are best-suited to workloads with very high-degrees of thread-level parallelism.
Due to both emerging programming models and better compiler support~\cite{NVIDIA2007,OpenCL:www,OpenACC:www}, this class of designs has found success in ``accelerating'' the key bottlenecks of a variety of domain-specific libraries and applications, including protein folding~\cite{5160922} and packet analysis for network security~\cite{fusco:2010:imc}, among numerous others (see below).
However, their ability to support scientific communities for grand challenges is endangered unless
software innovation finds sustainable ways to exploit the high degrees of parallelism necessary on such systems~\cite{patterson:2010:spectrum}, which as noted above also engender higher testing and debugging costs.

Within these broad classes, there are many variations based on a variety of techniques.
One prominent technique is hardware multithreading within a core in order to further tolerate latencies, which can be critical to hiding memory-wall bottlenecks~\cite{Alverson:1990mt,Wulf:1995mw}.
These accelerators tolerate latency
from accessing unpredictably scattered data by maintaining many execution threads. An execution
thread issues computational instructions once all outstanding memory references are satisfied. With
a deep enough queue of memory references and enough threads available, a processor can keep
all its execution units busy and achieve astounding efficiency.
Hardware multithreading can be combined with fine-grained synchronization support for further benefits.
For example, the Cray XMT~\cite{CrayInc.2007} achieves remarkable efficiency on
massive graph analysis by tolerating latencies all the way to its distributed memory units. Fine-grained
locking is ``free'' because it is amortized into the memory latency, and this permits automatic
optimization and software composition otherwise impossible. 
Simple software often achieves high
efficiency on multithreaded architecture, as illustrated by the efficient analysis of Twitter data
from 50,000 users for studying the spread of H1N1 influenza~\cite{Ediger2010a}. 
A more common variety of
multithreaded acceleration is available within Intel's Hyper-Threading (HT)~\cite{IntelCorp.2002,Riedy2011b,pasqual}. 
With
careful software design, HT has produced excellent results including the fastest, most reliable
single-node \textit{de novo} sequence assembler currently available~\cite{pasqual}.

\subsubsection{Graphics co-processors (GPUs) and Intel Xeon Phi (MIC)}
Within the class of throughput-optimized processors, graphics co-processors (GPUs) and Xeon Phi are being widely adopted in high-end systems for diverse applications in computational science and engineering.
Early successes appeared in the areas of molecular dynamics (MD) simulations~\cite{moleculardynamics},
dense linear algebra~\cite{denselinearalgebra}.
From this early enthusiasm, GPUs began to appear in cloud infrastructures, such as Amazon AWS/EC2~\cite{AmazonGPU}, and both GPUs and Phi feature prominently in the Top500 ranking of supercomputers~\cite{Meuer2013}.
These systems yielded have several Gordon Bell Prize winners in recent years~\cite{Hamada09,conf/sc/RahimianLVCMMSSVVZB10,Shimokawabe:2011:PPS:2063384.2063388}.

A key challenge in using platforms based on GPUs and Phi is that they often require substantial algorithmic and software redesign in order to exploit more cores, as well as additional degrees of tuning to exploit explicitly managed memories and data access aggregation to fully utilize the memory systems~\cite{Yang2007:gpu,Vuduc:2010kx}.
Despite these difficulties, there have been many successes, including sorting, FFTs,
wavelets, and dense matrix multiply; sparse conjugate gradient and
multi-grid; bioinformatics; relational joins for databases; quantum
chemistry; and the n-body problems; both for GPUs~\cite{NVIDIA.cuda.community,Choi:2014kl,Sao:2014wo} and Phi~\cite{Aluru:2014cg,Sarje:2013ap,Liu:2013sp,Liu:2014bs}.
However, productive and efficient use of these highly-capable GPGPUs
requires improved development environments that expose better
programming models, handle streaming data movement, and reduce
scheduling overheads~\cite{AugThiNamWac11CCPE}.

\subsubsection{Field Programmable Gate Arrays (FPGAs)}
Another trend is aggressive specialization.
These may include cores augmented with application-specific instructions or processing units.
Arguably the most aggressive form of specialization is the use of Field Programmable Gate Arrays (FPGAs), invented in the mid 1980s.
Vendors now manufacture FPGAs with multiple millions or billions of transistors.
The large size and architectural enhancements, 
including domain-specific feature sets, provide the needed versatility
to accelerate a wide range of applications on modern FPGAs. 
Scientific applications that have leveraged accelerated kernels on FPGAs include signal
and image processing \cite{Stitt:2011:E2EFPGA}, particle physics \cite{liu:2011:hades} and network
security \cite{jiang:2011:tvlsi}.

The building blocks of reconfigurable FPGA architecture are typically an array of logic blocks,
IO pads, routing channels, DSP blocks and internal RAM. Depending on the application, these
architectural elements are programmed to perform various functions. The logic and DSP blocks can
implement arithmetic and logic operations such as add, multiply, and compare. Their results flow
through the FPGAs using configurable routing channels with point-to-point dedicated interconnects
that avoid overheads, like cache misses, present in general processors. The ability to chain thousands
of operators with data routing between them make FPGAs an excellent platform for data flow
pipelines that can accelerate scientific applications with wide parallelism. 
Some metrics of the parallelism offered include~\cite{HPCFPGA} internal bandwidths of Terabytes/sec (TB/s) to move results between application logic blocks; throughputs of Tera-operations/sec (TOPS) for integer operations and Gigaflops/sec (GFLOPS) for floating point operations.
Several FPGA-based solutions are available from
HPC system vendors \cite{FPGA-Vendors} with associated 
compiler tools, libraries and services to program these systems. While several
science communities can leverage the immense acceleration offered by FPGAs, careful
consideration has to be given to restructure their algorithms to achieve potential
gains~\cite{Storaasli2007,Fu2009,Shafer2010,Convey,Baker2007,Yi2010,Putnam2009,Ganegedara2010,Hua2008}.


\subsubsection{Cloud Computing Platforms}
The phrase ``Cloud computing'' covers many levels of abstractions including virtualized dynamically
provisioned infrastructure, applications written under specific platforms and models like MapReduce,
and composable or self-contained application services. 
These infrastructure, platform, and software
as a service (IaaS, PaaS, SaaS) models are often layered. 
Cloud computing, particularly IaaS and
PaaS, is gaining support in the broader scientific community to provide on-demand and easy access
to computation and storage resources with low management overhead. 
External service providers with large data centers provision and manage elastic, 
virtual resources and lower barriers to entry.
Collocating massive datasets with large computing resources eases tackling
data-intensive grand challenge problems as demonstrated by Cloud projects
funded by DOE (Magellan~\cite{magellan}) and NSF (CluE~\cite{CluE} and
CiC~\cite{CiC}). 
Several open source Cloud fabrics~\cite{Euca, Nimbus} also exist.

Clouds require careful consideration, and our conceptual design will examine mapping applications
in biology, social science, and security to Cloud platforms. 
We will identify applications
that benefit from Clouds and also limitations in the Cloud software stack and programming models.
Clouds provide an easier platform for data collection and dissemination among large
pools of researchers and human subjects that is well suited for social sciences.
Computational biology and bioinformatics successfully leverage Cloud resources for
large scale tasks~\cite{langmead:Cloudsnp:2009, lu:azureblast:2010}.
Several efforts are on to build Science as a Service (ScaaS) for the biological
sciences community~\cite{carmen,myexperiment,Afgan2011}.

Not all science applications in our focus areas will map well to Cloud computing in their entirety.
Loosely coupled, task- and data- parallel applications are well suited for Clouds' relatively low
network bandwidth and high latency. 
Intermittent virtual resource performance and availability
also requires application resilience. 
Some key social network analysis kernels work well in the
MapReduce model~\cite{conf/icdm/KangTF09}, but overall the model is too constrained. 
More recent generalizations map
the bulk-synchronous processing (BSP) model to Cloud resources including Google's Pregel~\cite{conf/spaa/MalewiczABDHLC09}
for social network graph analysis, and UIUC's Sector and Sphere~\cite{conf/spaa/MalewiczABDHLC09,oai:arXiv.org:0808.3019}, 
opening Clouds to wider use in our science domains. 
In our experience, portions of applications that extract subsets of
massive, irregularly structured datasets can take advantage of Cloud computing's scale. 
The subset
then is passed to other computing platforms for analysis~\cite{Cloud.hybrid}. Multi-core processors and GPGPU's are
increasingly available within public Cloud
infrastructures~\cite{AmazonGPU} to support this hybrid model.
The conceptualization process, assisted by our synergistic activity~\cite{prasanna:cic:pillcrow}, will identify common
programming paradigms for utilizing Cloud resources, issues blocking wider adoption, and specific
aspects of grand challenge problems that are well suited for operating on Clouds.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "FPC_FinalReportMain"
%%% End: 
